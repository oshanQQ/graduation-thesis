{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d640c374-0a71-49ed-b6cc-598356426d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 layer perceptron\n",
      "========================================\n",
      "mnist_classification\n",
      "[-0.01285696  0.54008374 -0.25226827 -0.23678224]\n",
      "========================================\n",
      "cifar10_classification\n",
      "[-0.06620581  2.05091343 -5.68929198 -0.70034147]\n",
      "========================================\n",
      "cifar10_deep_classification\n",
      "[ 0.00952939  5.01498954  3.46986795 -1.62088255]\n",
      "========================================\n",
      "all_classification\n",
      "[-0.06986106  2.50171748 -3.68002805  0.94597626]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "print(\"2 layer perceptron\")\n",
    "for task in [\"mnist_classification\", \"cifar10_classification\", \"cifar10_deep_classification\", \"all_classification\"]:\n",
    "    print(\"=\" * 40)\n",
    "    print(task)\n",
    "\n",
    "    # Load the data into a pandas dataframe\n",
    "    df = pd.read_csv(f\"training_data/{task}.csv\")\n",
    "\n",
    "    # Split the data into input features (X) and output target (y)\n",
    "    X = df[['batch_size', 'epoch', 'average_memory_utilization', 'average_gpu_utilization']]\n",
    "    y = df['training_time']\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # sc = StandardScaler()\n",
    "    # sc.fit(X_train)\n",
    "    # X_train = sc.transform(X_train)\n",
    "    # X_test = sc.transform(X_test)\n",
    "\n",
    "    # Train a Perceptron model on the training data\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f9d8494-9b1e-4f78-b651-44f5f4bfbaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 layer perceptron\n",
      "========================================\n",
      "mnist_classification with epoch 10\n",
      "[-5.16420356e-03 -6.93889390e-18 -9.56317291e-02 -9.47985587e-02]\n",
      "mnist_classification with epoch 20\n",
      "[-8.75195641e-03 -2.77555756e-17 -1.12699399e-01 -2.49459936e-01]\n",
      "mnist_classification with epoch 30\n",
      "[-1.40625323e-02  2.77555756e-17 -2.36350960e-01 -3.89766403e-01]\n",
      "mnist_classification with epoch 40\n",
      "[-1.82072627e-02  5.55111512e-17 -4.02064961e-01 -3.55732133e-01]\n",
      "========================================\n",
      "cifar10_classification with epoch 10\n",
      "[-3.35750127e-02  8.88178420e-16 -3.29044844e+00 -6.08780206e-02]\n",
      "cifar10_classification with epoch 20\n",
      "[-5.78145765e-02 -2.22044605e-15 -6.16044441e+00 -2.64096297e-01]\n",
      "cifar10_classification with epoch 30\n",
      "[-9.16809403e-02  5.10702591e-15 -8.42391262e+00 -7.95474039e-01]\n",
      "cifar10_classification with epoch 40\n",
      "[-1.19230348e-01 -5.77315973e-15 -1.11134152e+01 -1.22187905e+00]\n",
      "========================================\n",
      "cifar10_deep_classification with epoch 10\n",
      "[ 3.61261643e-03 -2.22044605e-15  1.04330786e+00 -6.59023838e-01]\n",
      "cifar10_deep_classification with epoch 20\n",
      "[ 7.45090377e-03  1.33226763e-15  8.25013960e-01 -1.47493573e+00]\n",
      "cifar10_deep_classification with epoch 30\n",
      "[ 1.64177345e-02  1.11022302e-14  4.08298179e+00 -2.21071063e+00]\n",
      "cifar10_deep_classification with epoch 40\n",
      "[ 1.75281820e-02 -4.44089210e-15  3.67770352e+00 -2.94787510e+00]\n",
      "========================================\n",
      "all_classification with epoch 10\n",
      "[-2.91512564e-02 -1.39888101e-14 -1.47332109e+00  4.01861938e-01]\n",
      "all_classification with epoch 20\n",
      "[-5.47014873e-02  1.22124533e-14 -2.98182130e+00  7.69432492e-01]\n",
      "all_classification with epoch 30\n",
      "[-8.21470333e-02 -4.44089210e-15 -4.61961940e+00  1.11404227e+00]\n",
      "all_classification with epoch 40\n",
      "[-1.17281124e-01 -1.90958360e-14 -6.14423946e+00  1.48685121e+00]\n"
     ]
    }
   ],
   "source": [
    "print(\"2 layer perceptron\")\n",
    "for task in [\"mnist_classification\", \"cifar10_classification\", \"cifar10_deep_classification\", \"all_classification\"]:\n",
    "    print(\"=\" * 40)\n",
    "    for epoch in [10, 20, 30, 40]:\n",
    "        print(f\"{task} with epoch {epoch}\")\n",
    "\n",
    "        # Load the data into a pandas dataframe\n",
    "        df = pd.read_csv(f\"training_data/{task}_with_epoch_{epoch}.csv\")\n",
    "\n",
    "        # Split the data into input features (X) and output target (y)\n",
    "        X = df[['batch_size', 'epoch', 'average_memory_utilization', 'average_gpu_utilization']]\n",
    "        y = df['training_time']\n",
    "\n",
    "        # Split the data into training and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "        # sc = StandardScaler()\n",
    "        # sc.fit(X_train)\n",
    "        # X_train = sc.transform(X_train)\n",
    "        # X_test = sc.transform(X_test)\n",
    "\n",
    "        # Train a Perceptron model on the training data\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc879b61-e4af-428e-aec6-94263693fa57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
