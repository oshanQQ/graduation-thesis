{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6311345d-b232-48e0-9d38-47e94e276558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 06:41:41.896117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-10 06:41:41.914967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-10 06:41:41.915185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-10 06:41:41.915817: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-10 06:41:41.917204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-10 06:41:41.917408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-10 06:41:41.917536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-10 06:41:42.315809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-10 06:41:42.315983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-10 06:41:42.316085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-10 06:41:42.316196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4630 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:04:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "◆Train:\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 06:41:44.082647: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n",
      "2023-02-10 06:41:44.523376: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-10 06:41:44.523939: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-10 06:41:44.523960: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-02-10 06:41:44.524471: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-10 06:41:44.524529: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 3s 26ms/step - loss: 2.0443 - accuracy: 0.2387 - val_loss: 1.7266 - val_accuracy: 0.3694\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.7607 - accuracy: 0.3476 - val_loss: 1.5716 - val_accuracy: 0.4305\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.6126 - accuracy: 0.4070 - val_loss: 1.4467 - val_accuracy: 0.4792\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.5181 - accuracy: 0.4463 - val_loss: 1.3678 - val_accuracy: 0.5130\n",
      "Epoch 5/10\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 1.4512 - accuracy: 0.4753 - val_loss: 1.3147 - val_accuracy: 0.5292\n",
      "Epoch 6/10\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.4135 - accuracy: 0.4926 - val_loss: 1.2759 - val_accuracy: 0.5546\n",
      "Epoch 7/10\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.3642 - accuracy: 0.5126 - val_loss: 1.2453 - val_accuracy: 0.5572\n",
      "Epoch 8/10\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.3216 - accuracy: 0.5281 - val_loss: 1.2199 - val_accuracy: 0.5755\n",
      "Epoch 9/10\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.2893 - accuracy: 0.5385 - val_loss: 1.1652 - val_accuracy: 0.5879\n",
      "Epoch 10/10\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.2623 - accuracy: 0.5517 - val_loss: 1.1161 - val_accuracy: 0.6041\n",
      "\n",
      "Total training time: 16.62753200531006 seconds\n",
      "\n",
      "Average memory utilization during training so far: 9.122025062400002\n",
      "\n",
      "Average GPU utilization during training so far: 73.0\n",
      "Done\n",
      "Test Accuracy: 0.6040999889373779\n",
      "\n",
      "◆Train:\n",
      "Epoch 1/20\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 2.0306 - accuracy: 0.2335 - val_loss: 1.7282 - val_accuracy: 0.3827\n",
      "Epoch 2/20\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.7385 - accuracy: 0.3555 - val_loss: 1.5435 - val_accuracy: 0.4467\n",
      "Epoch 3/20\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.6020 - accuracy: 0.4128 - val_loss: 1.4464 - val_accuracy: 0.4792\n",
      "Epoch 4/20\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.5233 - accuracy: 0.4460 - val_loss: 1.3856 - val_accuracy: 0.4974\n",
      "Epoch 5/20\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.4607 - accuracy: 0.4740 - val_loss: 1.3614 - val_accuracy: 0.5246\n",
      "Epoch 6/20\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.4046 - accuracy: 0.4952 - val_loss: 1.2796 - val_accuracy: 0.5466\n",
      "Epoch 7/20\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.3616 - accuracy: 0.5129 - val_loss: 1.2292 - val_accuracy: 0.5622\n",
      "Epoch 8/20\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.3270 - accuracy: 0.5281 - val_loss: 1.2080 - val_accuracy: 0.5748\n",
      "Epoch 9/20\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.2937 - accuracy: 0.5419 - val_loss: 1.1761 - val_accuracy: 0.5860\n",
      "Epoch 10/20\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.2641 - accuracy: 0.5570 - val_loss: 1.1293 - val_accuracy: 0.6028\n",
      "Epoch 11/20\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.2353 - accuracy: 0.5670 - val_loss: 1.1136 - val_accuracy: 0.6112\n",
      "Epoch 12/20\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.2037 - accuracy: 0.5779 - val_loss: 1.0886 - val_accuracy: 0.6167\n",
      "Epoch 13/20\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.1869 - accuracy: 0.5846 - val_loss: 1.0694 - val_accuracy: 0.6210\n",
      "Epoch 14/20\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.1579 - accuracy: 0.5934 - val_loss: 1.0440 - val_accuracy: 0.6286\n",
      "Epoch 15/20\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 1.1372 - accuracy: 0.6003 - val_loss: 1.0669 - val_accuracy: 0.6102\n",
      "Epoch 16/20\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.1298 - accuracy: 0.6028 - val_loss: 1.0480 - val_accuracy: 0.6286\n",
      "Epoch 17/20\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.0917 - accuracy: 0.6171 - val_loss: 1.0030 - val_accuracy: 0.6450\n",
      "Epoch 18/20\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 1.0842 - accuracy: 0.6200 - val_loss: 1.0075 - val_accuracy: 0.6380\n",
      "Epoch 19/20\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.0625 - accuracy: 0.6279 - val_loss: 0.9943 - val_accuracy: 0.6478\n",
      "Epoch 20/20\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.0491 - accuracy: 0.6345 - val_loss: 0.9499 - val_accuracy: 0.6648\n",
      "\n",
      "Total training time: 29.723304271697998 seconds\n",
      "\n",
      "Average memory utilization during training so far: 10.216988262399997\n",
      "\n",
      "Average GPU utilization during training so far: 73.4\n",
      "Done\n",
      "Test Accuracy: 0.6647999882698059\n",
      "\n",
      "◆Train:\n",
      "Epoch 1/30\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 2.0756 - accuracy: 0.2275 - val_loss: 1.7763 - val_accuracy: 0.3730\n",
      "Epoch 2/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.7750 - accuracy: 0.3494 - val_loss: 1.5627 - val_accuracy: 0.4378\n",
      "Epoch 3/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.6478 - accuracy: 0.3960 - val_loss: 1.4797 - val_accuracy: 0.4761\n",
      "Epoch 4/30\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 1.5581 - accuracy: 0.4312 - val_loss: 1.3953 - val_accuracy: 0.5004\n",
      "Epoch 5/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.4959 - accuracy: 0.4570 - val_loss: 1.3399 - val_accuracy: 0.5206\n",
      "Epoch 6/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.4457 - accuracy: 0.4766 - val_loss: 1.3202 - val_accuracy: 0.5233\n",
      "Epoch 7/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.4102 - accuracy: 0.4919 - val_loss: 1.2563 - val_accuracy: 0.5444\n",
      "Epoch 8/30\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 1.3606 - accuracy: 0.5119 - val_loss: 1.2263 - val_accuracy: 0.5624\n",
      "Epoch 9/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.3358 - accuracy: 0.5250 - val_loss: 1.1934 - val_accuracy: 0.5721\n",
      "Epoch 10/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.3022 - accuracy: 0.5364 - val_loss: 1.1637 - val_accuracy: 0.5800\n",
      "Epoch 11/30\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 1.2692 - accuracy: 0.5481 - val_loss: 1.1258 - val_accuracy: 0.5999\n",
      "Epoch 12/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.2350 - accuracy: 0.5639 - val_loss: 1.1215 - val_accuracy: 0.5945\n",
      "Epoch 13/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.2118 - accuracy: 0.5717 - val_loss: 1.0849 - val_accuracy: 0.6156\n",
      "Epoch 14/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.2035 - accuracy: 0.5757 - val_loss: 1.0795 - val_accuracy: 0.6184\n",
      "Epoch 15/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.1659 - accuracy: 0.5887 - val_loss: 1.0566 - val_accuracy: 0.6261\n",
      "Epoch 16/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.1571 - accuracy: 0.5897 - val_loss: 1.0542 - val_accuracy: 0.6208\n",
      "Epoch 17/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.1400 - accuracy: 0.5978 - val_loss: 1.0509 - val_accuracy: 0.6240\n",
      "Epoch 18/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.1273 - accuracy: 0.6026 - val_loss: 1.0373 - val_accuracy: 0.6345\n",
      "Epoch 19/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.1078 - accuracy: 0.6123 - val_loss: 0.9921 - val_accuracy: 0.6492\n",
      "Epoch 20/30\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 1.0851 - accuracy: 0.6185 - val_loss: 0.9791 - val_accuracy: 0.6534\n",
      "Epoch 21/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.0734 - accuracy: 0.6231 - val_loss: 0.9690 - val_accuracy: 0.6576\n",
      "Epoch 22/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.0539 - accuracy: 0.6301 - val_loss: 0.9852 - val_accuracy: 0.6483\n",
      "Epoch 23/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.0565 - accuracy: 0.6296 - val_loss: 0.9558 - val_accuracy: 0.6654\n",
      "Epoch 24/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.0366 - accuracy: 0.6370 - val_loss: 0.9339 - val_accuracy: 0.6739\n",
      "Epoch 25/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.0273 - accuracy: 0.6401 - val_loss: 0.9471 - val_accuracy: 0.6657\n",
      "Epoch 26/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.0159 - accuracy: 0.6435 - val_loss: 0.9308 - val_accuracy: 0.6728\n",
      "Epoch 27/30\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.9897 - accuracy: 0.6541 - val_loss: 0.9089 - val_accuracy: 0.6824\n",
      "Epoch 28/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.9832 - accuracy: 0.6583 - val_loss: 0.9116 - val_accuracy: 0.6771\n",
      "Epoch 29/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.9768 - accuracy: 0.6587 - val_loss: 0.8990 - val_accuracy: 0.6848\n",
      "Epoch 30/30\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.9612 - accuracy: 0.6645 - val_loss: 0.8872 - val_accuracy: 0.6878\n",
      "\n",
      "Total training time: 44.45569562911987 seconds\n",
      "\n",
      "Average memory utilization during training so far: 11.284544307200001\n",
      "\n",
      "Average GPU utilization during training so far: 73.96666666666667\n",
      "Done\n",
      "Test Accuracy: 0.6877999901771545\n",
      "\n",
      "◆Train:\n",
      "Epoch 1/40\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 2.0665 - accuracy: 0.2355 - val_loss: 1.7945 - val_accuracy: 0.3680\n",
      "Epoch 2/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.7636 - accuracy: 0.3503 - val_loss: 1.5689 - val_accuracy: 0.4410\n",
      "Epoch 3/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.6331 - accuracy: 0.4005 - val_loss: 1.4686 - val_accuracy: 0.4814\n",
      "Epoch 4/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.5538 - accuracy: 0.4349 - val_loss: 1.3961 - val_accuracy: 0.5029\n",
      "Epoch 5/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.4883 - accuracy: 0.4595 - val_loss: 1.3370 - val_accuracy: 0.5289\n",
      "Epoch 6/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.4482 - accuracy: 0.4793 - val_loss: 1.2838 - val_accuracy: 0.5437\n",
      "Epoch 7/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.4087 - accuracy: 0.4956 - val_loss: 1.2920 - val_accuracy: 0.5442\n",
      "Epoch 8/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.3634 - accuracy: 0.5160 - val_loss: 1.2204 - val_accuracy: 0.5657\n",
      "Epoch 9/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.3198 - accuracy: 0.5303 - val_loss: 1.1869 - val_accuracy: 0.5791\n",
      "Epoch 10/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.3036 - accuracy: 0.5361 - val_loss: 1.2053 - val_accuracy: 0.5725\n",
      "Epoch 11/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.2680 - accuracy: 0.5542 - val_loss: 1.1348 - val_accuracy: 0.6001\n",
      "Epoch 12/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.2368 - accuracy: 0.5622 - val_loss: 1.1075 - val_accuracy: 0.6087\n",
      "Epoch 13/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.2106 - accuracy: 0.5706 - val_loss: 1.1052 - val_accuracy: 0.6091\n",
      "Epoch 14/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.1924 - accuracy: 0.5784 - val_loss: 1.0853 - val_accuracy: 0.6154\n",
      "Epoch 15/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.1827 - accuracy: 0.5820 - val_loss: 1.0806 - val_accuracy: 0.6231\n",
      "Epoch 16/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.1566 - accuracy: 0.5908 - val_loss: 1.0391 - val_accuracy: 0.6313\n",
      "Epoch 17/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.1460 - accuracy: 0.5983 - val_loss: 1.0540 - val_accuracy: 0.6308\n",
      "Epoch 18/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.1209 - accuracy: 0.6054 - val_loss: 1.0098 - val_accuracy: 0.6465\n",
      "Epoch 19/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.1063 - accuracy: 0.6106 - val_loss: 1.0285 - val_accuracy: 0.6357\n",
      "Epoch 20/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.0911 - accuracy: 0.6184 - val_loss: 0.9979 - val_accuracy: 0.6544\n",
      "Epoch 21/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.0819 - accuracy: 0.6197 - val_loss: 1.0246 - val_accuracy: 0.6365\n",
      "Epoch 22/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.0657 - accuracy: 0.6249 - val_loss: 0.9905 - val_accuracy: 0.6537\n",
      "Epoch 23/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.0456 - accuracy: 0.6348 - val_loss: 0.9554 - val_accuracy: 0.6680\n",
      "Epoch 24/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.0340 - accuracy: 0.6360 - val_loss: 0.9832 - val_accuracy: 0.6530\n",
      "Epoch 25/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.0240 - accuracy: 0.6407 - val_loss: 0.9420 - val_accuracy: 0.6700\n",
      "Epoch 26/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.0108 - accuracy: 0.6457 - val_loss: 0.9395 - val_accuracy: 0.6658\n",
      "Epoch 27/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.0022 - accuracy: 0.6508 - val_loss: 0.9234 - val_accuracy: 0.6762\n",
      "Epoch 28/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.9799 - accuracy: 0.6563 - val_loss: 0.9193 - val_accuracy: 0.6805\n",
      "Epoch 29/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.9869 - accuracy: 0.6532 - val_loss: 0.9372 - val_accuracy: 0.6715\n",
      "Epoch 30/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.9639 - accuracy: 0.6636 - val_loss: 0.9181 - val_accuracy: 0.6777\n",
      "Epoch 31/40\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.9638 - accuracy: 0.6616 - val_loss: 0.9577 - val_accuracy: 0.6584\n",
      "Epoch 32/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.9555 - accuracy: 0.6650 - val_loss: 0.9140 - val_accuracy: 0.6790\n",
      "Epoch 33/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.9416 - accuracy: 0.6682 - val_loss: 0.9069 - val_accuracy: 0.6844\n",
      "Epoch 34/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.9279 - accuracy: 0.6754 - val_loss: 0.9041 - val_accuracy: 0.6877\n",
      "Epoch 35/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.9224 - accuracy: 0.6772 - val_loss: 0.9123 - val_accuracy: 0.6766\n",
      "Epoch 36/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.9103 - accuracy: 0.6813 - val_loss: 0.9005 - val_accuracy: 0.6876\n",
      "Epoch 37/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.9068 - accuracy: 0.6834 - val_loss: 0.9007 - val_accuracy: 0.6860\n",
      "Epoch 38/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.8901 - accuracy: 0.6887 - val_loss: 0.8681 - val_accuracy: 0.7007\n",
      "Epoch 39/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.8832 - accuracy: 0.6897 - val_loss: 0.8571 - val_accuracy: 0.7023\n",
      "Epoch 40/40\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.8789 - accuracy: 0.6918 - val_loss: 0.8577 - val_accuracy: 0.6970\n",
      "\n",
      "Total training time: 58.89836859703064 seconds\n",
      "\n",
      "Average memory utilization during training so far: 12.099118796800001\n",
      "\n",
      "Average GPU utilization during training so far: 73.875\n",
      "Done\n",
      "Test Accuracy: 0.6970000267028809\n",
      "\n",
      "◆Train:\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 2.0969 - accuracy: 0.2195 - val_loss: 1.7877 - val_accuracy: 0.3571\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.7933 - accuracy: 0.3358 - val_loss: 1.5846 - val_accuracy: 0.4321\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.6487 - accuracy: 0.3930 - val_loss: 1.4704 - val_accuracy: 0.4671\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.5665 - accuracy: 0.4262 - val_loss: 1.4467 - val_accuracy: 0.4826\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.5163 - accuracy: 0.4459 - val_loss: 1.3686 - val_accuracy: 0.5075\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.4604 - accuracy: 0.4714 - val_loss: 1.3366 - val_accuracy: 0.5084\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.4215 - accuracy: 0.4869 - val_loss: 1.2628 - val_accuracy: 0.5481\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.3939 - accuracy: 0.4996 - val_loss: 1.2300 - val_accuracy: 0.5647\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.3500 - accuracy: 0.5142 - val_loss: 1.2447 - val_accuracy: 0.5615\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.3210 - accuracy: 0.5262 - val_loss: 1.1818 - val_accuracy: 0.5799\n",
      "\n",
      "Total training time: 15.001644372940063 seconds\n",
      "\n",
      "Average memory utilization during training so far: 13.0654711808\n",
      "\n",
      "Average GPU utilization during training so far: 76.9\n",
      "Done\n",
      "Test Accuracy: 0.5799000263214111\n",
      "\n",
      "◆Train:\n",
      "Epoch 1/20\n",
      "63/63 [==============================] - 2s 29ms/step - loss: 2.0964 - accuracy: 0.2224 - val_loss: 1.8221 - val_accuracy: 0.3520\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.8036 - accuracy: 0.3387 - val_loss: 1.6046 - val_accuracy: 0.4305\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.6562 - accuracy: 0.3950 - val_loss: 1.4739 - val_accuracy: 0.4682\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.5590 - accuracy: 0.4333 - val_loss: 1.4092 - val_accuracy: 0.4981\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.4780 - accuracy: 0.4652 - val_loss: 1.3553 - val_accuracy: 0.5154\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.4427 - accuracy: 0.4812 - val_loss: 1.3211 - val_accuracy: 0.5298\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.3904 - accuracy: 0.5012 - val_loss: 1.3250 - val_accuracy: 0.5295\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.3540 - accuracy: 0.5184 - val_loss: 1.2373 - val_accuracy: 0.5608\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.3208 - accuracy: 0.5312 - val_loss: 1.2070 - val_accuracy: 0.5751\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.3018 - accuracy: 0.5398 - val_loss: 1.1785 - val_accuracy: 0.5868\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.2633 - accuracy: 0.5547 - val_loss: 1.1398 - val_accuracy: 0.5976\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.2292 - accuracy: 0.5648 - val_loss: 1.1009 - val_accuracy: 0.6149\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.2046 - accuracy: 0.5745 - val_loss: 1.1224 - val_accuracy: 0.6055\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.1946 - accuracy: 0.5780 - val_loss: 1.1084 - val_accuracy: 0.6152\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.1616 - accuracy: 0.5935 - val_loss: 1.0594 - val_accuracy: 0.6262\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.1431 - accuracy: 0.5993 - val_loss: 1.0373 - val_accuracy: 0.6376\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.1207 - accuracy: 0.6068 - val_loss: 1.0697 - val_accuracy: 0.6203\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.1225 - accuracy: 0.6079 - val_loss: 1.0181 - val_accuracy: 0.6428\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.0899 - accuracy: 0.6179 - val_loss: 0.9958 - val_accuracy: 0.6545\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.0853 - accuracy: 0.6192 - val_loss: 1.0152 - val_accuracy: 0.6415\n",
      "\n",
      "Total training time: 29.319920539855957 seconds\n",
      "\n",
      "Average memory utilization during training so far: 10.5123588096\n",
      "\n",
      "Average GPU utilization during training so far: 75.0\n",
      "Done\n",
      "Test Accuracy: 0.6414999961853027\n",
      "\n",
      "◆Train:\n",
      "Epoch 1/30\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 2.0431 - accuracy: 0.2333 - val_loss: 1.7100 - val_accuracy: 0.3916\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.7311 - accuracy: 0.3595 - val_loss: 1.5478 - val_accuracy: 0.4433\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.6084 - accuracy: 0.4083 - val_loss: 1.4511 - val_accuracy: 0.4792\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.5311 - accuracy: 0.4407 - val_loss: 1.3718 - val_accuracy: 0.5043\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.4798 - accuracy: 0.4624 - val_loss: 1.3407 - val_accuracy: 0.5240\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.4262 - accuracy: 0.4846 - val_loss: 1.3009 - val_accuracy: 0.5292\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.3823 - accuracy: 0.5004 - val_loss: 1.2361 - val_accuracy: 0.5597\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.3594 - accuracy: 0.5135 - val_loss: 1.2285 - val_accuracy: 0.5626\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.3173 - accuracy: 0.5279 - val_loss: 1.1992 - val_accuracy: 0.5750\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.2745 - accuracy: 0.5457 - val_loss: 1.1640 - val_accuracy: 0.5864\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.2566 - accuracy: 0.5517 - val_loss: 1.1388 - val_accuracy: 0.5899\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.2225 - accuracy: 0.5640 - val_loss: 1.1077 - val_accuracy: 0.6065\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.2052 - accuracy: 0.5720 - val_loss: 1.0939 - val_accuracy: 0.6129\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.1780 - accuracy: 0.5828 - val_loss: 1.0724 - val_accuracy: 0.6201\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.1484 - accuracy: 0.5942 - val_loss: 1.0789 - val_accuracy: 0.6187\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.1348 - accuracy: 0.6011 - val_loss: 1.0423 - val_accuracy: 0.6321\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.1177 - accuracy: 0.6058 - val_loss: 1.0279 - val_accuracy: 0.6369\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.0973 - accuracy: 0.6156 - val_loss: 1.0527 - val_accuracy: 0.6301\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.0919 - accuracy: 0.6157 - val_loss: 1.0140 - val_accuracy: 0.6404\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.0658 - accuracy: 0.6247 - val_loss: 0.9936 - val_accuracy: 0.6472\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.0533 - accuracy: 0.6316 - val_loss: 0.9712 - val_accuracy: 0.6598\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.0458 - accuracy: 0.6317 - val_loss: 0.9638 - val_accuracy: 0.6578\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.0227 - accuracy: 0.6403 - val_loss: 0.9475 - val_accuracy: 0.6671\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.0102 - accuracy: 0.6455 - val_loss: 0.9640 - val_accuracy: 0.6639\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.0159 - accuracy: 0.6463 - val_loss: 0.9699 - val_accuracy: 0.6561\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.9931 - accuracy: 0.6532 - val_loss: 0.9318 - val_accuracy: 0.6742\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.9806 - accuracy: 0.6570 - val_loss: 0.9164 - val_accuracy: 0.6753\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.9744 - accuracy: 0.6604 - val_loss: 0.9208 - val_accuracy: 0.6751\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.9596 - accuracy: 0.6634 - val_loss: 0.8964 - val_accuracy: 0.6866\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.9477 - accuracy: 0.6692 - val_loss: 0.9162 - val_accuracy: 0.6753\n",
      "\n",
      "Total training time: 43.33228421211243 seconds\n",
      "\n",
      "Average memory utilization during training so far: 11.570251912533333\n",
      "\n",
      "Average GPU utilization during training so far: 76.1\n",
      "Done\n",
      "Test Accuracy: 0.6753000020980835\n",
      "\n",
      "◆Train:\n",
      "Epoch 1/40\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 2.0600 - accuracy: 0.2318 - val_loss: 1.7769 - val_accuracy: 0.3654\n",
      "Epoch 2/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.7592 - accuracy: 0.3553 - val_loss: 1.5528 - val_accuracy: 0.4445\n",
      "Epoch 3/40\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.6115 - accuracy: 0.4126 - val_loss: 1.4345 - val_accuracy: 0.4801\n",
      "Epoch 4/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.5183 - accuracy: 0.4504 - val_loss: 1.3722 - val_accuracy: 0.5110\n",
      "Epoch 5/40\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.4585 - accuracy: 0.4751 - val_loss: 1.3156 - val_accuracy: 0.5341\n",
      "Epoch 6/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.4092 - accuracy: 0.4963 - val_loss: 1.2503 - val_accuracy: 0.5489\n",
      "Epoch 7/40\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.3563 - accuracy: 0.5163 - val_loss: 1.2100 - val_accuracy: 0.5718\n",
      "Epoch 8/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.3328 - accuracy: 0.5270 - val_loss: 1.1870 - val_accuracy: 0.5774\n",
      "Epoch 9/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.2843 - accuracy: 0.5456 - val_loss: 1.1748 - val_accuracy: 0.5829\n",
      "Epoch 10/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.2689 - accuracy: 0.5522 - val_loss: 1.1388 - val_accuracy: 0.5997\n",
      "Epoch 11/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.2422 - accuracy: 0.5605 - val_loss: 1.0968 - val_accuracy: 0.6080\n",
      "Epoch 12/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.2187 - accuracy: 0.5707 - val_loss: 1.1292 - val_accuracy: 0.6026\n",
      "Epoch 13/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.1856 - accuracy: 0.5812 - val_loss: 1.0719 - val_accuracy: 0.6242\n",
      "Epoch 14/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.1789 - accuracy: 0.5839 - val_loss: 1.0685 - val_accuracy: 0.6189\n",
      "Epoch 15/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.1508 - accuracy: 0.5959 - val_loss: 1.0294 - val_accuracy: 0.6352\n",
      "Epoch 16/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.1259 - accuracy: 0.6028 - val_loss: 1.0048 - val_accuracy: 0.6435\n",
      "Epoch 17/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.1124 - accuracy: 0.6086 - val_loss: 1.0377 - val_accuracy: 0.6384\n",
      "Epoch 18/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.1044 - accuracy: 0.6144 - val_loss: 1.0070 - val_accuracy: 0.6481\n",
      "Epoch 19/40\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.0760 - accuracy: 0.6229 - val_loss: 0.9999 - val_accuracy: 0.6465\n",
      "Epoch 20/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.0681 - accuracy: 0.6243 - val_loss: 0.9747 - val_accuracy: 0.6533\n",
      "Epoch 21/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.0575 - accuracy: 0.6292 - val_loss: 0.9501 - val_accuracy: 0.6662\n",
      "Epoch 22/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.0400 - accuracy: 0.6349 - val_loss: 0.9437 - val_accuracy: 0.6676\n",
      "Epoch 23/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.0181 - accuracy: 0.6432 - val_loss: 0.9636 - val_accuracy: 0.6633\n",
      "Epoch 24/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.0219 - accuracy: 0.6426 - val_loss: 0.9286 - val_accuracy: 0.6738\n",
      "Epoch 25/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.9947 - accuracy: 0.6499 - val_loss: 0.9091 - val_accuracy: 0.6806\n",
      "Epoch 26/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.9999 - accuracy: 0.6530 - val_loss: 0.9597 - val_accuracy: 0.6683\n",
      "Epoch 27/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.9759 - accuracy: 0.6572 - val_loss: 0.9032 - val_accuracy: 0.6840\n",
      "Epoch 28/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.9562 - accuracy: 0.6648 - val_loss: 0.9083 - val_accuracy: 0.6817\n",
      "Epoch 29/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.9508 - accuracy: 0.6682 - val_loss: 0.9020 - val_accuracy: 0.6839\n",
      "Epoch 30/40\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.9436 - accuracy: 0.6703 - val_loss: 0.8733 - val_accuracy: 0.6936\n",
      "Epoch 31/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.9243 - accuracy: 0.6760 - val_loss: 0.9014 - val_accuracy: 0.6885\n",
      "Epoch 32/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.9184 - accuracy: 0.6802 - val_loss: 0.8699 - val_accuracy: 0.6976\n",
      "Epoch 33/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.9010 - accuracy: 0.6863 - val_loss: 0.8592 - val_accuracy: 0.6978\n",
      "Epoch 34/40\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.8900 - accuracy: 0.6888 - val_loss: 0.8374 - val_accuracy: 0.7051\n",
      "Epoch 35/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.8891 - accuracy: 0.6900 - val_loss: 0.8615 - val_accuracy: 0.6951\n",
      "Epoch 36/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.8878 - accuracy: 0.6903 - val_loss: 0.8478 - val_accuracy: 0.7061\n",
      "Epoch 37/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.8693 - accuracy: 0.6955 - val_loss: 0.8258 - val_accuracy: 0.7106\n",
      "Epoch 38/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.8698 - accuracy: 0.6956 - val_loss: 0.8411 - val_accuracy: 0.7055\n",
      "Epoch 39/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.8462 - accuracy: 0.7038 - val_loss: 0.8302 - val_accuracy: 0.7136\n",
      "Epoch 40/40\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.8379 - accuracy: 0.7065 - val_loss: 0.8251 - val_accuracy: 0.7113\n",
      "\n",
      "Total training time: 57.73445963859558 seconds\n",
      "\n",
      "Average memory utilization during training so far: 12.4684944384\n",
      "\n",
      "Average GPU utilization during training so far: 75.975\n",
      "Done\n",
      "Test Accuracy: 0.7113000154495239\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import psutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super(CustomCallback, self).__init__()\n",
    "        self.training_time = None\n",
    "        self.average_memory_utilization = None\n",
    "        self.average_gpu_utilization = None\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.start_time = time.time()\n",
    "        self.memory_utilizations = []\n",
    "        self.gpu_utilizations = []\n",
    "        \n",
    "    def on_train_end(self, logs={}):\n",
    "        self.training_time = time.time() - self.start_time\n",
    "        self.average_memory_utilization = np.mean(self.memory_utilizations)\n",
    "        self.average_gpu_utilization = np.mean(self.gpu_utilizations)\n",
    "        print('\\nTotal training time: {} seconds'.format(self.training_time))\n",
    "        print('\\nAverage memory utilization during training so far: {}'.format(self.average_memory_utilization))\n",
    "        print('\\nAverage GPU utilization during training so far: {}'.format(self.average_gpu_utilization))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        memory_utilization = psutil.virtual_memory().used / pow(10, 9) # ex. 8.6Gi\n",
    "        gpu_utilization_process = subprocess.Popen(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader'], stdout=subprocess.PIPE)\n",
    "        gpu_utilization = int(gpu_utilization_process.stdout.readline().strip().decode('utf-8').split()[0])\n",
    "        self.memory_utilizations.append(memory_utilization)\n",
    "        self.gpu_utilizations.append(gpu_utilization)\n",
    "\n",
    "        \n",
    "def Classify(batch_size, epochs):\n",
    "    # Load the CIFAR10 dataset\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "    # Preprocess the data\n",
    "    x_train = x_train / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "\n",
    "    # Build the model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"\\n◆Train:\")\n",
    "    callback = CustomCallback()\n",
    "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), callbacks=[callback])\n",
    "    print(\"Done\")\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"Test Accuracy:\", test_acc)\n",
    "    \n",
    "    with open('cifar10_classification.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([batch_size, epochs, callback.average_memory_utilization, callback.average_gpu_utilization, callback.training_time, test_loss, test_acc])\n",
    "\n",
    "        \n",
    "for batch in range(100, 801, 100):\n",
    "    for epoch in range(10, 41, 10):\n",
    "        Classify(batch, epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f8211-4538-4fae-a9c3-7a1bb580ad5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
